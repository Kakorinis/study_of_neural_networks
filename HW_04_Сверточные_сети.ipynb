{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "__Домашнее задание:__<br>\n",
        "обучить рукописную сверточную нейронную сеть (с падением размера ядра свертки и последовательностью блоков свертка-пулинг (conv-pool)-(conv-pool)-...) на датасете cifar-10<br>\n",
        "оценить рост точности при увеличении ширины сети (больше фильтров)\n",
        "оценить рост точности при увеличении глубины сети (больше слоев)\n",
        "*сравнить с точностью полносвязной сети для этой выборки\n",
        "\n",
        "<br>\n",
        "\n",
        "Рекомендации по оформлению кода:\n",
        "исправляя код из ноутбука, указывайте, пожалуйста, где были сделаны изменения, чтобы было легче ориентироваться в коде, к тому же это повысит скорость проверки работы."
      ],
      "metadata": {
        "id": "z3hgRe7Kyhsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Решение:__\n",
        "\n",
        "Загружаю библиотеки"
      ],
      "metadata": {
        "id": "7gHTS64cC_QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import Model \n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "\n"
      ],
      "metadata": {
        "id": "RduC4fVJzI-D"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаю картинки и рабиваю на трейн и тест:"
      ],
      "metadata": {
        "id": "6FJVC7rODZRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'тренировочные примеры')\n",
        "print(X_test.shape[0], 'тестовые примеры')\n",
        "\n",
        "classes = ['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0wwIpAyypzw",
        "outputId": "220e70d3-21f4-4def-cd46-54e36fffcee5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# смотрю диапазон значений в данных, т.к. они не объединены, проверяю и в тесте и в трейне\n",
        "X_train.min(), X_train.max(), X_test.min(), X_test.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRFIqrwQEafT",
        "outputId": "38b1147e-d1e2-40d7-fd3b-076caa75aae0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255, 0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# перевожу таргеты в виде чисел в векторное выражение\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# нормирую данные с учетом увиденных выше макс. значений\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "4bSQRwS6zcer"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "К примеру возьмем 101-ое изображение и посмотрим что за картинки:"
      ],
      "metadata": {
        "id": "2Ccy-1q6FNzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 101\n",
        "\n",
        "plt.imshow(X_test[N])\n",
        "plt.title(classes[np.argmax(y_test[N,:])])\n",
        "plt.xlabel(f'img.shape: {X_test[N].shape}', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "lDNwenuizlch",
        "outputId": "be9af9f7-2c69-4037-ffad-d69cb1675279"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим картинку 32х32.\n",
        "\n",
        "__Приступаю к написанию нейросети:__ возьму 3 сверточных слоя и после каждого из них будет пулинговый, далее 2 полносвязных слоя"
      ],
      "metadata": {
        "id": "6rYH4MhhFbqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # сверточные и пуллинговые слои - 3 шт.\n",
        "    Conv2D(2, (4, 4), padding='same', input_shape=(32, 32, 3)),  # input_shape берем из X_train.shape[1:], ядро берем размером 4х4\n",
        "    AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),  # padding - обрабатываю края картинки (доп. контурный пискельный ряд по периметру), pool_size 2х2 матрица\n",
        "    Conv2D(5, (3, 3), padding='same'),  \n",
        "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), # strides здесь уже будем не каждый подряд пискель ядром 2х2 просматривать, а перепрыгивать ч-з 1\n",
        "    Conv2D(9, (3, 3), padding='same'),\n",
        "    AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # 2 полносвязных слоя               # полносвязных нужно делать более 1 слоя, чтобы уходить от линейной зависимости\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(80, activation='relu'),\n",
        "\n",
        "    # выходной слой\n",
        "    Dense(10, activation='softmax')\n",
        "    ])  \n",
        "\n",
        "# компиляция модели\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='Adam',\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "hist = model.fit(X_train, y_train,\n",
        "                 epochs=2,\n",
        "                 batch_size=1000,\n",
        "                 validation_data=(X_test, y_test),\n",
        "                 verbose=1)\n",
        "#model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OpX4qwn1D-4",
        "outputId": "62846d04-1659-4c35-fa7d-a1b50747dcd1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 64s 1s/step - loss: 2.0906 - accuracy: 0.2410 - val_loss: 1.9232 - val_accuracy: 0.3065\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 62s 1s/step - loss: 1.8423 - accuracy: 0.3466 - val_loss: 1.7814 - val_accuracy: 0.3706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ради эксперимента попробую применить к модели аугментацию и посмотреть на итог:"
      ],
      "metadata": {
        "id": "pNMwyxH7FzNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('То же самое, но с использованием data augmentation')\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False, \n",
        "    zca_epsilon=1e-06, \n",
        "    rotation_range=10, \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0., \n",
        "    zoom_range=0.2, \n",
        "    channel_shift_range=0.,\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    rescale=None,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    validation_split=0.0)\n",
        "\n",
        "\n",
        "train_gen = datagen.flow(X_train, \n",
        "                          y_train,\n",
        "                          batch_size=1000)\n",
        "\n",
        "# запуск data augmentation через fit_generator\n",
        "model.fit(train_gen,\n",
        "          epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m58TO6UCLe-",
        "outputId": "d1ad4daa-085c-40b3-a1a7-2c4b38575a6e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "То же самое, но с использованием data augmentation\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 81s 2s/step - loss: 1.8025 - accuracy: 0.3583 - val_loss: 1.6806 - val_accuracy: 0.4109\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 72s 1s/step - loss: 1.7325 - accuracy: 0.3816 - val_loss: 1.6236 - val_accuracy: 0.4259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0eca94bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEdn0r6E-J8B",
        "outputId": "452be645-7d6b-4770-b520-99dd6397123c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 32, 32, 2)         98        \n",
            "                                                                 \n",
            " average_pooling2d_30 (Avera  (None, 32, 32, 2)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 32, 32, 5)         95        \n",
            "                                                                 \n",
            " average_pooling2d_31 (Avera  (None, 16, 16, 5)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 16, 16, 9)         414       \n",
            "                                                                 \n",
            " average_pooling2d_32 (Avera  (None, 16, 16, 9)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 120)               276600    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 80)                9680      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 287,697\n",
            "Trainable params: 287,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, возьму model как за базовую сеть и далее буду результаты сравнивать с ней.<br>\n",
        "model генерирует 287 697 признака и accuracy: 0.3466\n",
        "\n",
        "__На основе базовой модели напишу модель с увеличенной шириной сети (больше фильтров):__"
      ],
      "metadata": {
        "id": "kUmkh86aGE4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# практики ради буду использовать др. способ написания сети (ручной)\n",
        "\n",
        "# инициализация  модели\n",
        "input = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "# первый сверточный слой\n",
        "x1 = layers.Conv2D(6, (4, 4), strides=(1, 1),     # меняю кол-во входных карт(фильтров) с 3 на 6\n",
        "                   activation='relu',\n",
        "                   padding=\"same\")(input)\n",
        "\n",
        "# первый пуллинговый слой\n",
        "x2 = layers.AveragePooling2D(pool_size=(2, 2),\n",
        "                             strides=(1, 1),\n",
        "                             padding='same')(x1)\n",
        "\n",
        "# второй сверточный слой\n",
        "x3 = layers.Conv2D(8, (3, 3), strides=(2, 2),    # меняю кол-во входных карт(фильтров) с 5 на 8\n",
        "                   activation='relu',\n",
        "                   padding='same')(x2)\n",
        "\n",
        "# второй пуллинговый слой\n",
        "x4 = layers.AveragePooling2D(pool_size=(2, 2),\n",
        "                             strides=(2, 2),\n",
        "                             padding='same')(x3)\n",
        "\n",
        "# третий сверточный слой\n",
        "x5 = layers.Conv2D(9, (3, 3), strides=(1, 1),   # оставлю д т.к. итак должна получиться широкая сеть - увидим в summary()\n",
        "                   activation='relu',\n",
        "                   padding='valid')(x4)\n",
        "\n",
        "# третий пуллинговый слой\n",
        "x6 = layers.AveragePooling2D(pool_size=(2, 2),\n",
        "                             strides=(1, 1),\n",
        "                             padding='same')(x5)\n",
        "\n",
        "\n",
        "\n",
        "# сглаживание CNN выхода чтобы можно было его присоединить к полносвязногому слою\n",
        "x7 = layers.Flatten()(x6)\n",
        "\n",
        "# полносвязный слой                              \n",
        "x8 = layers.Dense(120, activation='tanh')(x7)\n",
        "# полносвязный слой\n",
        "x9 = layers.Dense(80, activation='tanh')(x8)\n",
        "\n",
        "# выходной слой с функцией активации softmax\n",
        "out_x = layers.Dense(10, activation='softmax')(x9)\n",
        "\n",
        "\n",
        "# Соберем полную модель сети от входа к выходу \n",
        "model_wider = Model(inputs=input, outputs=out_x)\n",
        "\n",
        "# сделаем несколько промежуточных выходов (через них посмотрим, что происходит в сети) \n",
        "model_1_layer = Model(inputs=input, outputs=x1)\n",
        "model_3_layer = Model(inputs=input, outputs=x3)\n",
        "\n",
        "model_wider.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2vAh6BJ7DC0",
        "outputId": "1a0448d6-caca-4f82-9503-d270f4e19756"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 32, 32, 6)         294       \n",
            "                                                                 \n",
            " average_pooling2d_33 (Avera  (None, 32, 32, 6)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 16, 16, 8)         440       \n",
            "                                                                 \n",
            " average_pooling2d_34 (Avera  (None, 8, 8, 8)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 6, 6, 9)           657       \n",
            "                                                                 \n",
            " average_pooling2d_35 (Avera  (None, 6, 6, 9)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 324)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 120)               39000     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 80)                9680      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,881\n",
            "Trainable params: 50,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, более широкая модель генерирует 50 881 признаков, что заметно меньше признаков чем первая - 287 697. <br>\n",
        "\n",
        "Также более широкая модель на третьем  сверточном слое имеет меньшую размерность - 6х6\n",
        "\n",
        "Посмотрим на ее точность предсказания:"
      ],
      "metadata": {
        "id": "M-WL3zxOLzTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# компиляция модели\n",
        "model_wider.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='Adam',\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "hist = model_wider.fit(X_train, y_train,\n",
        "                 epochs=2,\n",
        "                 batch_size=1000,\n",
        "                 validation_data=(X_test, y_test),\n",
        "                 verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mZ0JkAqMKAC",
        "outputId": "e16427cd-9bd8-4740-e933-6474b148d80f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 34s 678ms/step - loss: 2.1020 - accuracy: 0.2298 - val_loss: 1.8986 - val_accuracy: 0.3318\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 1.8141 - accuracy: 0.3480 - val_loss: 1.7333 - val_accuracy: 0.3817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно сказать что ширина не повлияла на точность предсказания.\n",
        "\n",
        "__Теперь попробую на основе базовой модели увеличить глубину сети (больше слоев) и сравнить итог:__"
      ],
      "metadata": {
        "id": "C7Uvl6L3M_D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_deeper = Sequential([\n",
        "    # сверточные и пуллинговые слои - вместо 3 сверточных сделаю 6, булинговые оставлю как есть 3 шт.\n",
        "    Conv2D(2, (4, 4), padding='same', input_shape=(32, 32, 3)),\n",
        "    Conv2D(2, (3, 3), padding='same'),                                       # доп. сверточ. слой №1\n",
        "    AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),  \n",
        "    Conv2D(5, (3, 3), padding='same'),\n",
        "    Conv2D(5, (3, 3), padding='same'),                                       # доп. сверточ. слой №2\n",
        "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), \n",
        "    Conv2D(9, (3, 3), padding='same'),\n",
        "    Conv2D(9, (3, 3), padding='same'),                                      # доп. сверточ. слой №3\n",
        "    AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # 2 полносвязных слоя               # полносвязные не буду менять, т.к. задача в том, чтобы тестить сверточные слои\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(80, activation='relu'),\n",
        "\n",
        "    # выходной слой\n",
        "    Dense(10, activation='softmax')\n",
        "    ])  \n",
        "\n",
        "# компиляция модели\n",
        "model_deeper.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='Adam',\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "hist = model_deeper.fit(X_train, y_train,\n",
        "                 epochs=2,\n",
        "                 batch_size=1000,\n",
        "                 validation_data=(X_test, y_test),\n",
        "                 verbose=1)\n",
        "\n",
        "model_deeper.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm80YVYqNTCT",
        "outputId": "52ab6cd3-53c7-4166-e5f2-a795281a8e08"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 106s 2s/step - loss: 2.0036 - accuracy: 0.2835 - val_loss: 1.7894 - val_accuracy: 0.3636\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 103s 2s/step - loss: 1.6949 - accuracy: 0.3990 - val_loss: 1.6365 - val_accuracy: 0.4156\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 32, 32, 2)         98        \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 32, 32, 2)         38        \n",
            "                                                                 \n",
            " average_pooling2d_36 (Avera  (None, 32, 32, 2)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 32, 32, 5)         95        \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 32, 32, 5)         230       \n",
            "                                                                 \n",
            " average_pooling2d_37 (Avera  (None, 16, 16, 5)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 16, 16, 9)         414       \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 16, 16, 9)         738       \n",
            "                                                                 \n",
            " average_pooling2d_38 (Avera  (None, 16, 16, 9)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 120)               276600    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 80)                9680      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 288,703\n",
            "Trainable params: 288,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Вывод:__ базовая и более широкая модель выдали accuracy: 0.34 в то время как более глубокая модель показывает результат лучше: 0.39 и при этом кол-во признаков у нее сопоставимо с кол-вом у базовой модели. Вероятно эффективнее строить более глубокие, а не широкие сети."
      ],
      "metadata": {
        "id": "8D_nPKVuHKvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ради любопытства посмотрим как более глубокая модель отработает с аугментацией\n",
        "\n",
        "model_deeper.fit(train_gen,\n",
        "          epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72G05i9WRB8k",
        "outputId": "27a3d853-e1cd-483e-8520-ea37e51c9ef9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 123s 2s/step - loss: 1.6968 - accuracy: 0.3958 - val_loss: 1.5478 - val_accuracy: 0.4566\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 115s 2s/step - loss: 1.6358 - accuracy: 0.4186 - val_loss: 1.5234 - val_accuracy: 0.4621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ecc05adf0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Базовая модель показывала accuracy 0.38, здесь же видим 0.41\n",
        "\n",
        "__Из идей что еще добавить в модел:__ Dropout и BatchNormalization"
      ],
      "metadata": {
        "id": "T8_J-NBRPsu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers import Dropout\n",
        "# Dropout(rate=0.5)\n",
        "\n",
        "\n",
        "# from keras.layers import BatchNormalization\n",
        "# Sequential([\n",
        "#     BatchNormalization(input_shape=(8, 8, 2))\n",
        "# ]).summary()"
      ],
      "metadata": {
        "id": "xJPQd2jlDbKa"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}