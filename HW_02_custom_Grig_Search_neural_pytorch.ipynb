{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Добиться хорошего результата от модели, собранной на занятии (5 угаданныx картинок из 8 предложенных). Варианты изменений:<br>\n",
        "изменение слоёв и их количества;<br>\n",
        "изменение метода оптимизации;<br>\n",
        "изменение процесса обучения;<br>\n",
        "*преобразование данных transform<br>\n",
        "2.*Переписать данный туториал на PyTorch: https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ru"
      ],
      "metadata": {
        "id": "EG2W3WNsZb6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "74RBhHvaa4hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kJcL2mfTiQD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Ниже перепишу часть кода с урока и непосредственно саму модель, которую нужно улучшить:__"
      ],
      "metadata": {
        "id": "z8qfM-NMTEgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАГРУЗКА ТРЕЙНА И ТЕСТА\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
        "                                             train=True,  # можно таким же образом скачать тестовую часть\n",
        "                                             transform=transforms.ToTensor(), #чтобы сразу преобразовывалось в корректный тип и тут нормировка происходит сразу \n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "image, label = train_dataset[0]\n",
        "print(image.size())\n",
        "print(label)"
      ],
      "metadata": {
        "id": "tFOgzIysbHR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt требует классического вида shape, потому преобразовали через пермут\n",
        "\n",
        "plt.imshow(image.permute(1, 2, 0).numpy()); # 1 2 0 - это индексы изначальноых параметров image"
      ],
      "metadata": {
        "id": "45VL9lb6bf9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# НАСТРОЙКА ПОДАЧИ КАРТИНОК С ТЕСТА  ТРЕЙНА В DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, # какой кусок объектов выдавать. 64 картинки\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "-5nsgoGWb0E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# НАЗВАНИЯ КЛАССОВ ДАТАСЕТА - ВСЕГО 10 КЛАССОВ\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "8ABSsgWscCHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# МОДЕЛЬ С УРОКА\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 4 * hidden_dim)     # инициализиурем 4 слоя\n",
        "        self.fc2 = nn.Linear(4 * hidden_dim, 2 * hidden_dim)\n",
        "        self.fc3 = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1) # вытягиваем в одномерный вектор - аналог flatten\n",
        "        x = self.fc1(x)      # прононяем по первому слою\n",
        "        x = F.leaky_relu(x)  # применяем функцию активации лики релу\n",
        "        x = self.fc2(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc4(x)      # на четвертом слое не сделали ф-цию активации, тут многоклассовость и д.б. софт макс, мы ее в предсказании сделаем\n",
        "        return x             # в прямом проходе всегда следует останавливаться на том, что идет в ф-цию активации в конце и не писать ее,т.к. ф-ции потерь считаются в торче\n",
        "                             # на логитах, а логиты это то что идет в ф-цию активации\n",
        "    \n",
        "    def predict(self, x):            # тот же форвард, но с софтмаксов на конце (выделяет 1 класс из логитов)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc2(x) \n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = F.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net(3072, 100, 10)  # 3072 это кол-во каналов при входе усноженное на размерность картинки: 3 * 32 * 32\n",
        "net.train()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # ф-ция потерь в торче использует именно логиты. получается что с forward поступают логиты и она их считывает, поэтому нет в конце активации выше\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.0) # net.parameters() это мы так указываем подгружая параметры модели\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_items = 0.0\n",
        "\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "         # Обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        # Делаем предсказание\n",
        "        outputs = net(inputs)\n",
        "        # Рассчитываем лосс-функцию\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Делаем шаг назад по лоссу\n",
        "        loss.backward()\n",
        "        # Делаем шаг нашего оптимайзера\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}')\n",
        "            running_loss, running_items = 0.0, 0.0\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "id": "0Uy2pLcdTm64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ДАЛЕЕ КАЧЕСТВО РАБОТЫ МОДЕЛИ -СМОТРИМ МЕТРИКУ И ПРЕДМЕСТНО КАК УГАДЫВАЕТ КАРТИНКИ\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)"
      ],
      "metadata": {
        "id": "recHw65MUKwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "outputs = net(images)  # говорит что net(images) это равнозначно net.forward(images) типа можно упрощать \n",
        "imgs = torchvision.utils.make_grid(images)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(imgs.permute(1, 2, 0).numpy())\n",
        "print('GroundTruth: ', ' '.join(classes[labels[j]] for j in range(len(labels))))"
      ],
      "metadata": {
        "id": "ZvAnEHLXUUvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "predicted"
      ],
      "metadata": {
        "id": "bngpJBfkUarQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt = np.array([classes[labels[j]] for j in range(len(labels))])\n",
        "pred = np.array([classes[predicted[j]] for j in range(len(labels))])\n",
        "\n",
        "print(gt)\n",
        "print(pred)\n",
        "print(f'Accuracy is {(gt == pred).sum() / len(gt)}')"
      ],
      "metadata": {
        "id": "ihtbF_F4Ue4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__РЕШЕНИЕ:__<br>\n",
        "Cначала проверяем предоставляет ли в данный момент колаб возможность использования GPU.\n",
        "<br>\n",
        "\n",
        "если да, то в цикле ниже и модель и все inputs, labels (трейн и предсказание)нужно положить на GPU через метод .to_device(device)\n",
        "\n",
        "На этапе выполнения 72 итераций ниже я подключил себе версию про на колабе и имел доступ к видеокарте НВИДИА с 40гб. памяти, в гугл колабе на странице данной работы в рантайме включил GPU и потом на gpu клал саму тестируемую модель нейросети и inputs & labels (все входы в нее), однако на скорость обучения это не повлияло - увидим ниже."
      ],
      "metadata": {
        "id": "ekweG6rzFUIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Поддерживается ли CUDA : {torch.cuda.is_available()}\")\n",
        "print(f'Количество гпу девайсов: {torch.cuda.device_count()}')\n",
        "print(f\"Характеристики видеокарты : {torch.cuda.get_device_properties(0)}\")\n",
        "print(f\"Удаляем всю незанятую память через torch.cuda.empty_cache()\")"
      ],
      "metadata": {
        "id": "5m9b3se7FTH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "b7DdEfdSGMqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Я решил одновременно прогонять по циклу и смотреть качество работы моделей по следующим параметрам:__\n",
        "* кол-во скрытых слоев нейросети (для этого ниже настроил универсальный способ создания сети),\n",
        "* кол-во нейронов,\n",
        "* кол-во эпох обучения каждой сети,\n",
        "* скорость обучения оптимизатора."
      ],
      "metadata": {
        "id": "1yxwSQY4Wg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# МОЯ ХИТРО НАПИСАННАЯ МОДЕЛЬ С ВОЗМОЖНОСТЬЮ АВТОМАТИЧЕСКОГО СОЗДАНИЯ СКРЫТЫХ СЛОЕВ СКОЛЬКО ХОЧЕШЬ \n",
        "class My_Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers=3):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        \n",
        "        # ниже примерная логика как можно изменять кол-во нейронов от слоя к слою, чтобы выходные из предыдущего равнялись кол-ву входных следующего слоя\n",
        "        self.layers.append(nn.Linear(input_dim, (2 ** (n_layers - 2)) * hidden_dim)) # первый слой вне цикла, т.к. инпуты тут фиксированные, а в цикле будем подбирать\n",
        "        for i in range(1, n_layers - 1): #  ВООБЩЕ ХОТЕЛОСЬ БЫ чтобы  n_layers отображал именно кол-во скрытых слоев, а не всего слоев\n",
        "          self.layers.append(nn.Linear((2 ** (n_layers - i - 1)) * hidden_dim, (2 ** (n_layers - i - 2)) * hidden_dim))\n",
        "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)         # вытягиваем в одномерный вектор - аналог flatten\n",
        "        for layer in self.layers[:-1]: # последний не берем, т.к. для него не нужна активация\n",
        "          x = layer(x)             # прононяем по слою\n",
        "          x = F.leaky_relu(x)      # применяем функцию активации лики релу\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "  \n"
      ],
      "metadata": {
        "id": "weKfr7OxArLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Далее будет долгий цикл и чтобы колаб не спрашивал подверждения что я работ при ожидании обучения нейросети в не активном режиме (я ушел от компа), настроил кликер в javascript браузера (в консоли инспектора)__\n",
        "\n",
        "<br>\n",
        "Steps <br>\n",
        "    Сначала создать пустую строку ввода кода - туда нажать курсор и далее по схеме:<br>\n",
        "    Open the inspector view by typing Ctrl+ Shift + i and then clicking on console tab at top.\n",
        "    Paste the below code snippet at bottom of console and hit enter\n",
        "\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "RfTBJPTUZ1gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Ниже идет тот самый долгий цикл, где я перебираю каждую модель и после последней эпохи записываю параметры, в т.ч. время обучения в секундах. Решил проблему обнуления весов у одной и той же модели, но где перебирается разное кол-во эпох. Все вроде бы корректно.__\n",
        "\n",
        "<br>\n",
        "\n",
        "__Примечание по рассчету кросс-энтропии:__ Похоже что, встроенная функция расчитыват усредненный лосс на батче. Поэтому надо в конце эпохи делить аккумулятивный лосс на количество батчей, а не на количество картинок. Именно поэтому лоссы на тесте и на трейне на порядок не сходились в методичке"
      ],
      "metadata": {
        "id": "rbXgtx5lXpcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "\n",
        "num_layers = range(3, 7) # мой класс нейросети Net написан так, что число отсюда это кол-во всего слоев, чтобы увидеть именно число скрытых слоев, нужно отнять 2 (входной, выходной)\n",
        "n_dims = [10, 30, 50] # в модели нейросети на разных слоях кол-во нейронов будет исчисляться путем умножения взятого числа из n_dims на число от 2 до 8\n",
        "num_epochs = [5,10,20]\n",
        "lr_rate = [0.0001, 0.001]\n",
        "\n",
        "# сюда буду записывать параметры каждой модели\n",
        "results = pd.DataFrame(columns=['hidden dim', 'learning rate','epochs', 'time (sec)','train loss','test loss', 'train acc', 'test acc'])\n",
        "\n",
        "count = 1\n",
        "for l in num_layers:\n",
        "  for dim in n_dims:\n",
        "    torch.cuda.empty_cache()\n",
        "    net_to_examine = Net(input_dim=3072, hidden_dim=dim, output_dim=10, n_layers=l).to(device)  # 3072 размерность картинки * входы: 32*32*3, а 10 - кол-во классов\n",
        "\n",
        "    for rate in lr_rate:\n",
        "      optimizer = optim.Adam(net_to_examine.parameters(), lr=rate)\n",
        "\n",
        "      for n in num_epochs:\n",
        "        start = time.time() # буду сравнивать время обучения каждой модели\n",
        "\n",
        "        # включаем обучение\n",
        "        net_to_examine.train()\n",
        "\n",
        "        for epoch in range(n):\n",
        "            running_loss = 0.0\n",
        "            running_items = 0.0\n",
        "            running_loss_test = 0.0\n",
        "            running_items_test = 0.0\n",
        "            running_right = 0.0\n",
        "            running_right_test = 0.0\n",
        "\n",
        "            #net_to_examine.train() сли тут, то последние веса прошлой модели идут в первую эпоху следующей модели\n",
        "            for i, data in enumerate(train_loader):\n",
        "                \n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                # Обнуляем градиент внутри каждой эпохи итерируемых эпох 1 модели\n",
        "                optimizer.zero_grad()\n",
        "                # Делаем предсказание\n",
        "                outputs = net_to_examine(inputs)\n",
        "                # Рассчитываем лосс-функцию\n",
        "                loss = criterion(outputs, labels)\n",
        "                # Делаем шаг назад по лоссу\n",
        "                loss.backward()\n",
        "                # Делаем шаг нашего оптимайзера\n",
        "                optimizer.step()\n",
        "\n",
        "                # выводим статистику о процессе обучения\n",
        "                running_loss += loss.item()\n",
        "                running_items += len(labels)\n",
        "                running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "\n",
        "            running_right = running_right.item()\n",
        "            train_loss = running_loss / i\n",
        "            train_acc = running_right / running_items\n",
        "            print(f'Epoch [{epoch + 1}/{n}]. ' \\\n",
        "                  f'Loss_train: {train_loss:.4f}. ' \\\n",
        "                  f'Acc: {train_acc:.4f}.', end=' ')\n",
        "            \n",
        "\n",
        "            net_to_examine.eval()\n",
        "            for i, data in enumerate(test_loader):\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                # Делаем предсказание\n",
        "                outputs = net_to_examine(inputs)\n",
        "                # Рассчитываем лосс-функцию\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_loss_test += loss.item()\n",
        "                running_items_test += len(labels)\n",
        "                running_right_test += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "\n",
        "            running_right_test = running_right_test.item()\n",
        "            test_loss = running_loss_test / i\n",
        "            test_acc = running_right_test / running_items_test\n",
        "            print(f'Loss_test: {test_loss:.4f}. ' \\\n",
        "                  f'Acc_test: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "            # итерация одной модели со всеми проверяемыми параметрами заканчивается после отработки последней эпохи и именно тут записыываем скор и считаем время\n",
        "            if (epoch +1) == n:\n",
        "              end = time.time() - start\n",
        "              results = results.append({'hidden layers': l-2,  # считать буду только скрытые слои, т.к. именно эта инф. полезна - зачем учитывать входной и выходной слой\n",
        "                              'hidden dim': dim,\n",
        "                              'learning rate': rate,\n",
        "                              'epochs': n,\n",
        "                              'time (sec)': int(end),\n",
        "                              'train loss': train_loss,\n",
        "                              'test loss': test_loss,\n",
        "                              'train acc': train_acc, \n",
        "                              'test acc': test_acc}, ignore_index=True)\n",
        "              \n",
        "              # чтобы понимать сколько еще осталось ждать до окончания цикла\n",
        "              print(f'Завершилось обучение модели № {count} из {len(n_dims)*len(num_epochs)*len(lr_rate)*len(num_layers)}\\n')\n",
        "              count += 1\n",
        "\n",
        "              if count % 24 == 0:\n",
        "                results.to_csv(f'Grid_Search_result 1 - {count}.csv', index = False)\n",
        "                files.download('Grid_Search_result 1 - {count}.csv')\n",
        "\n",
        "              #перезаписывая модель заново таким образом обнуляю веса с последней эпохи  перед включением трейна обратно\n",
        "              net_to_examine = Net(input_dim=3072, hidden_dim=dim, output_dim=10, n_layers=l).to(device)\n",
        "              optimizer = optim.Adam(net_to_examine.parameters(), lr=rate)\n",
        "\n",
        "            # независимо последняя эпоха или нет, после каждой эпохи обнуляем значения для подсчета метрик\n",
        "            running_loss_test, running_items_test, running_right_test = 0.0, 0.0, 0.0\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "\n",
        "print('Training is finished!')\n",
        "\n",
        "results.to_csv('Grid_Search_result FINAL.csv', index = False)\n",
        "files.download('Grid_Search_result FINAL.csv')"
      ],
      "metadata": {
        "id": "RUcxQje6D2cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Я скачивал в цикле данные и по итогам цикла и далее я сейчас погружу весь результат работы цикла (чтобы заново не запускать цикл):__"
      ],
      "metadata": {
        "id": "ssGVeD89YKNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ГБ/выборки для исследований/Grid_Search_result FINAL.csv', \"rb\") as f:\n",
        "    results = pd.read_csv(f)\n",
        "    \n",
        "results"
      ],
      "metadata": {
        "id": "8g8KvRnGBuuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# т.к. время в секундах, то хочу веревести в минуты\n",
        "results['time (sec)'] = results['time (sec)'].apply(lambda x: float(str(f'{x / 60: .2f}')))"
      ],
      "metadata": {
        "id": "Y9vZONjvY3S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "HUUtN5yQZkZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# чтобы название теперь соответствовало цифрам перепишу его - можно было сразу сделать в цикле кстати\n",
        "results.rename(columns={'time (sec)': 'time (min)'}, inplace=true)\n",
        "results.head(3)"
      ],
      "metadata": {
        "id": "tY2CP5hyfS79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['time (sec)'].sum() / 60"
      ],
      "metadata": {
        "id": "okNMauG6Zqv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Цикл работал 3.5 часа!"
      ],
      "metadata": {
        "id": "ZvL_Lw6GAIXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сортирую датафрейм так чтобы сверху был лучший скор и одновременно меньшее время обучения\n",
        "results.sort_values(['test acc','time (sec)'], ascending=[False, True]).head(9)"
      ],
      "metadata": {
        "id": "ouPie-GZAxqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим что победила 68 модель (индекс здесь соответствует номеру итерации в цикле и сотв-но номеру модели).\n",
        "\n",
        "<br> \n",
        "\n",
        "Создам теперь модель именно с этими параметрами и буду ожидать от нее 52% точности на тесте:"
      ],
      "metadata": {
        "id": "zqfE9youaoFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_net = My_Net(input_dim=3072, hidden_dim=50, output_dim=10, n_layers=6) # n_layers указываю на 2 больше, т.к. 4 в таблице это именно\n",
        "                                                                                       # скрытые слои, т.е. без учета входного и выходного слоя\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "final_optimizer = optim.Adam(final_net.parameters(), lr=0.0001)    \n",
        "epochs = 20\n",
        "\n",
        "# обучения\n",
        "for epoch in range(epochs):\n",
        "    final_net.train() # поскольку у меня в цикле обучения внедрена часть кода проверки предсказания на тесте, то в предсказнии обучени отключаю, а перед обучением надо включать\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_items = 0.0\n",
        "    running_loss_test = 0.0\n",
        "    running_items_test = 0.0\n",
        "    running_right = 0.0\n",
        "    running_right_test = 0.0\n",
        "\n",
        "    #net_to_examine.train() сли тут, то последние веса прошлой модели идут в первую эпоху следующей модели\n",
        "    for i, data in enumerate(train_loader):\n",
        "        \n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # Обнуляем градиент внутри каждой эпохи итерируемых эпох \n",
        "        final_optimizer.zero_grad()\n",
        "        # Делаем предсказание\n",
        "        outputs = final_net(inputs)\n",
        "        # Рассчитываем лосс-функцию\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Делаем шаг назад по лоссу\n",
        "        loss.backward()\n",
        "        # Делаем шаг нашего оптимайзера\n",
        "        final_optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "\n",
        "    running_right = running_right.item()\n",
        "    train_loss = running_loss / i\n",
        "    train_acc = running_right / running_items\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "          f'Loss_train: {train_loss:.4f}. ' \\\n",
        "          f'Acc: {train_acc:.4f}.', end=' ')\n",
        "    \n",
        "\n",
        "    final_net.eval()\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs, labels = data[0], data[1]\n",
        "        # Делаем предсказание\n",
        "        outputs = final_net(inputs)\n",
        "        # Рассчитываем лосс-функцию\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss_test += loss.item()\n",
        "        running_items_test += len(labels)\n",
        "        running_right_test += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "\n",
        "    running_right_test = running_right_test.item()\n",
        "    test_loss = running_loss_test / i\n",
        "    test_acc = running_right_test / running_items_test\n",
        "    print(f'Loss_test: {test_loss:.4f}. ' \\\n",
        "          f'Acc_test: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "    # независимо последняя эпоха или нет, после каждой эпохи обнуляем значения для подсчета метрик\n",
        "    running_loss_test, running_items_test, running_right_test = 0.0, 0.0, 0.0\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0"
      ],
      "metadata": {
        "id": "ka67fF0Oa9uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Финальная часть - смотрим как распознает картинки на примере:__"
      ],
      "metadata": {
        "id": "tx6He3tmgKVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "final_net.eval()\n",
        "outputs = final_net(images)  # final_net(images) это равнозначно final_net.forward(images) - можно упрощать \n",
        "imgs = torchvision.utils.make_grid(images)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(imgs.permute(1, 2, 0).numpy())\n",
        "print('GroundTruth: ', ' '.join(classes[labels[j]] for j in range(len(labels))))"
      ],
      "metadata": {
        "id": "GtjNq7aPUGeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "predicted"
      ],
      "metadata": {
        "id": "O_YbtFeCf92H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt = np.array([classes[labels[j]] for j in range(len(labels))])\n",
        "pred = np.array([classes[predicted[j]] for j in range(len(labels))])\n",
        "\n",
        "print(gt)\n",
        "print(pred)\n",
        "print(f'Accuracy is {(gt == pred).sum() / len(gt)}')"
      ],
      "metadata": {
        "id": "ujIkhvBuYe_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, модель распознала 5 из 8.\n",
        "\n",
        "Попробуем сделать то же самое, но без деления на батчи в критерии (делаем как на уроке было):"
      ],
      "metadata": {
        "id": "YVUK3edkilZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_net2 = My_Net(input_dim=3072, hidden_dim=50, output_dim=10, n_layers=6) # n_layers указываю на 2 больше, т.к. 4 в таблице это именно\n",
        "                                                                                       # скрытые слои, т.е. без учета входного и выходного слоя\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "final_optimizer = optim.Adam(final_net2.parameters(), lr=0.0001)    \n",
        "\n",
        "num_epochs = 20  \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_items = 0.0\n",
        "    \n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0], data[1]\n",
        "        \n",
        "        # Обнуляем градиент\n",
        "        final_optimizer.zero_grad()\n",
        "        # Делаем предсказание\n",
        "        outputs = final_net2(inputs)\n",
        "        # Рассчитываем лосс-функцию\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Делаем шаг назад по лоссу\n",
        "        loss.backward()\n",
        "        # Делаем шаг нашего оптимайзера\n",
        "        final_optimizer.step()\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        if i % 300 ==0:  # печатаем каждые 300 mini-batches\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}')\n",
        "            running_loss, running_items = 0.0, 0.0\n",
        "            \n",
        "print('Training is finished!')\n",
        "\n"
      ],
      "metadata": {
        "id": "O6dKiAvujYd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "final_net2.eval()\n",
        "outputs = final_net2(images)  # final_net(images) это равнозначно final_net.forward(images) - можно упрощать \n",
        "imgs = torchvision.utils.make_grid(images)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(imgs.permute(1, 2, 0).numpy())\n",
        "print('GroundTruth: ', ' '.join(classes[labels[j]] for j in range(len(labels))))"
      ],
      "metadata": {
        "id": "HEBbIrL4kEtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "gt = np.array([classes[labels[j]] for j in range(len(labels))])\n",
        "pred = np.array([classes[predicted[j]] for j in range(len(labels))])\n",
        "\n",
        "print(gt)\n",
        "print(pred)\n",
        "print(f'Number of matches is {(gt == pred).sum()}')\n",
        "print(f'Accuracy is {(gt == pred).sum() / len(gt)}')"
      ],
      "metadata": {
        "id": "ZNFis_U_kPIj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}